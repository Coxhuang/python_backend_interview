[TOC]

# Python面试题

## #1 数据库MySQL 


### #1.1 事务

#### #1.1.1 MySQL事务特性

> 事务（transaction）是作为一个单元的一组有序的数据库操作。如果组中的所有操作都成功，则认为事务成功，即使只有一个操作失败，事务也不成功。如果所有操作完成，事务则提交，其修改将作用于所有其他数据库进程。如果一个操作失败，则事务将回滚，该事务所有操作的影响都将取消。

一般来说，事务是必须满足4个条件（ACID）：原子性（Atomicity，或称不可分割性）、一致性（Consistency）、隔离性（Isolation，又称独立性）、持久性（Durability）。

- 原子性：一个事务（transaction）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。
- 一致性：在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。
- 隔离性：数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。
- 持久性：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。

#### #1.1.2 为什么要设置隔离级别

**在数据库操作中，在并发的情况下可能出现如下问题**：

- 更新丢失（Lost update） 
- 脏读（Dirty Reads） 
- 不可重复读（Non-repeatable Reads） 
- 幻象读 

> 更新丢失（Lost update）

如果多个线程操作，基于同一个查询结构对表中的记录进行修改，那么后修改的记录将会覆盖前面修改的记录，前面的修改就丢失掉了，这就叫做更新丢失。这是因为系统没有执行任何的锁操作，因此并发事务并没有被隔离开来。 

第1类丢失更新：事务A撤销时，把已经提交的事务B的更新数据覆盖了。 

![20200226164721-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200226164721-image.png)

第2类丢失更新：事务A覆盖事务B已经提交的数据，造成事务B所做的操作丢失。 

![20200226164822-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200226164822-image.png)

解决方法：==对行加锁，只允许并发一个更新事务。==

> 脏读（Dirty Reads） 

A事务读取B事务尚未提交的数据并在此基础上操作，而B事务执行回滚，那么A读取到的数据就是脏数据。

![20200226165330-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200226165330-image.png)

==解决办法：如果在第一个事务提交前，任何其他事务不可读取其修改过的值，则可以避免该问题。==

> 不可重复读（Non-repeatable Reads） 

一个事务对同一行数据重复读取两次，但是却得到了不同的结果。事务T1读取某一数据后，事务T2对其做了修改，当事务T1再次读该数据时得到与前一次不同的值。 

![20200226165445-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200226165445-image.png)

==解决办法：如果只有在修改事务完全提交之后才可以读取数据，则可以避免该问题。==

> 幻象读 

指两次执行同一条 select 语句会出现不同的结果，第二次读会增加一数据行，并没有说这两次执行是在同一个事务中。一般情况下，幻象读应该正是我们所需要的。但有时候却不是，如果打开的游标，在对游标进行操作时，并不希望新增的记录加到游标命中的数据集中来。隔离级别为 游标稳定性 的，可以阻止幻象读。例如：目前工资为1000的员工有10人。那么事务1中读取所有工资为1000的员工，得到了10条记录；这时事务2向员工表插入了一条员工记录，工资也为1000；那么事务1再次读取所有工资为1000的员工共读取到了11条记录。 


![20200226165834-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200226165834-image.png)

==解决办法：如果在操作事务完成数据处理之前，任何其他事务都不可以添加新数据，则可避免该问题==


#### #1.1.3 事务的隔离级别

数据库事务的隔离级别有4个，由低到高依次为:
- Read uncommitted(未授权读取、读未提交)
- Read committed（授权读取、读提交）
- Repeatable read（可重复读取）
- Serializable（序列化）

**这四个级别可以逐个解决脏读、不可重复读、幻象读这几类问题。**

> Read uncommitted(未授权读取、读未提交)

如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。这样就避免了更新丢失，却可能出现脏读。也就是说事务B读取到了事务A未提交的数据。

> Read committed（授权读取、读提交）

读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。该隔离级别避免了脏读，但是却可能出现不可重复读。事务A事先读取了数据，事务B紧接了更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变。

> Repeatable read（可重复读取）

可重复读是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，即使第二个事务对数据进行修改，第一个事务两次读到的的数据是一样的。这样就发生了在一个事务内两次读到的数据是一样的，因此称为是可重复读。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。这样避免了不可重复读取和脏读，但是有时可能出现幻象读。（读取数据的事务）这可以通过“共享读锁”和“排他写锁”实现。


> Serializable（序列化）

提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。序列化是最高的事务隔离级别，同时代价也花费最高，性能很低，一般很少使用，在该级别下，事务顺序执行，不仅可以避免脏读、不可重复读，还避免了幻像读。 







### #1.2 存储引擎


#### #1.2.1 Mysql中有哪些存储引擎? 

- MyISAM
- Heap
- Merge
- INNODB
- ISAM


#### #1.2.2 简述在MySQL数据库中MyISAM和InnoDB的区别

> InnoDB

- 支持ACID的事务，支持事务的四种隔离级别；
- 支持行级锁及外键约束：因此可以支持写并发；
- 不存储总行数；
- 一个InnoDb引擎存储在一个文件空间（共享表空间，表大小不受操作系统控制，一个表可能分布在多个文件里），也有可能为多个（设置为独立表空，表大小受操作系统文件大小限制，一般为2G），受操作系统文件大小的限制；
- 主键索引采用==聚集索引==（索引的数据域存储数据文件本身），辅索引的数据域存储主键的值；因此从辅索引查找数据，需要先通过辅索引找到主键值，再访问辅索引；最好使用自增主键，防止插入数据时，为维持B+树结构，文件的大调整。


> MyISAM

- 不支持事务，但是每次查询都是原子的；
- 支持表级锁，即每次操作是对整个表加锁；
- 存储表的总行数；
- 一个MYISAM表有三个文件：索引文件、表结构文件、数据文件；
- 采用==非聚集索引==，索引文件的数据域存储指向数据文件的指针。辅索引与主索引基本一致，但是辅索引不用保证唯一性。



#### #1.2.3 如何选择InnoDB/MyISAM

- InnoDB

**需要提交/回滚/崩溃恢复,要求实现高并发控制的时候选择InnoDB**

- MyISAM

**数据表主要用来插入和查询记录,MyISAM能提供较高的处理效率**


### #1.3 索引


#### #1.3.1 索引分类

- 普通索引
- 唯一索引
- 主键索引
- 组合索引

> 普通索引

普通索引（由关键字KEY或INDEX定义的索引）的唯一任务是加快对数据的访问速度。

```
CREATE INDEX index_name ON table(column)
```

修改表时加索引语句：

```
ALTER TABLE table_name ADD INDEX index_name ON (column)
```

> 唯一索引

索引列的值必须唯一，但允许有空值。如果是组合索引，则列值的组合必须唯一。

```
CREATE UNIQUE INDEX indexName ON table(column)
```

修改表时加索引语句：

```
ALTER TABLE table_name ADD UNIQUE indexName ON (column)
```

> 主键索引

是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引。

```
CREATE TABLE 'table' (
    'id' int(11) NOT NULL AUTO_INCREMENT ,   
    PRIMARY KEY ('id')
);
```

> 组合索引

用户可以在多个列上建立索引,这种索引叫做复合索引(组合索引) 查询时使用创建时第一个开始 索引才有效 使用遵循左前缀集合

```
ALTER TABLE `table` ADD INDEX indexName (name,xb,age); 
```

#### #1.3.2 索引使用的注意事项

- 索引要用在where条件==经常使用的列==上
- 加索引的列,内容==不要频繁变化==
- 加索引列的值可以为null,并且可以有多null,但==不能存有重复的空字符串' '== 
- 对于创建多个列索引,如果不是一起使用的话,则查询时使用索引会不起作用,如(创建索引A和索引B,但是只查询了A)
- 模糊查询时,使用==like前面==有百分号开头索引会失效,如("%kobe%"这样所以会失效,但是"kobe%"这样子,索引可以正常使用)
- 如果条件中or,那么条件中带索引会失效，就是说必须作为条件的所有字段都必须带索引 ，建议不要使用or关键字
- 如果列类型是字符串，哪作为条件查询时该列的值一定用' '引号引用起来，否则索引失效


#### #1.3.3 性别字段为什么不适合加索引

尽量选择区分度高的字段作为索引,区分度的公式是 count(distinct col)/count(*)，表示 字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是 1，而一些状态、 性别字段可能在大数据面前区分度就是 0。在性别字段上增加索引，并不能明显加快检索速度


#### #1.3.4 什么情况下设置了索引但无法使用


- 以“%”开头的LIKE语句，模糊匹配
- OR语句前后没有同时使用索引
- 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）
- 模糊查询时,使用==like前面==有百分号开头索引会失效,如("%kobe%"这样所以会失效,但是"kobe%"这样子,索引可以正常使用)


#### #1.3.5 简单描述mysql中，索引，主键，唯一索引，联合索引的区别，对数据库的性能有什么影响（从读写两方面）


- 索引是一种特殊的文件(InnoDB数据表上的索引是表空间的一个组成部分)，它们包含着对数据表里所有记录的引用指针。
- 普通索引(由关键字KEY或INDEX定义的索引)的唯一任务是加快对数据的访问速度。
- 普通索引允许被索引的数据列包含重复的值。如果能确定某个数据列将只包含彼此各不相同的值，在为这个数据列创建索引的时候就应该用关键字UNIQUE把它定义为一个唯一索引。也就是说，唯一索引可以保证数据记录的唯一性。
- 主键，是一种特殊的唯一索引，在一张表中只能定义一个主键索引，主键用于唯一标识一条记录，使用关键字 PRIMARY KEY 来创建。
- 索引可以覆盖多个数据列，如像INDEX(columnA, columnB)索引，这就是联合索引。

> 索引可以极大的提高数据的查询速度，但是会降低插入、删除、更新表的速度，因为在执行这些写操作时，还要操作索引文件。

#### #1.3.6 索引的目的是什么？

- 快速访问数据表中的特定信息，提高检索速度
- 创建唯一性索引，保证数据库表中每一行数据的唯一性。
- 加速表和表之间的连接

> 使用分组和排序子句进行数据检索时，可以显著减少查询中分组和排序的时间

#### #1.3.7 索引对数据库系统的负面影响是什么？

创建索引和维护索引需要耗费时间，这个时间随着数据量的增加而增加；索引需要占用物理空间，不光是表需要占用数据空间，每个索引也需要占用物理空间；当对表进行增、删、改、的时候索引也要动态维护，这样就降低了数据的维护速度。

#### #1.3.8 什么情况下不宜建立索引？

- 对于查询中很少涉及的列或者重复值比较多的列，不宜建立索引。
- 对于一些特殊的数据类型，不宜建立索引，比如文本字段（text）等


#### #1.3.9 组合索引和单列索引如何选择? 

- 如果查询where条件只有一个,那么使用单列索引速度快,索引所占空间也比较小
- 如果业务中经常查询多列,不要试图分别基于单个列去建单列索引(因为虽然是多个单列索引,但是MySQL只能用到那个它认为似乎最有效率的单列索引),这是因为当SQL语句所查询的列,全部都出现在复合索引中,此时由于只需要查询索引块即可获得所有数据,当然比使用多个单列索引要快的多.


#### 1.3.10 


### #1.4 锁


#### #1.4.1 Mysql中有哪几种锁？

- 表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。
- 行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
- 页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。

> 行锁是InnoDB默认的锁,但是在筛选条件中没有索引字段就会锁住整张表


#### #1.4.2 乐观锁与悲观锁 

1. 定义

乐观锁:

> 假设认为数据一般情况下不会造成冲突,所以在数据进行提交更新时,才会正式对数据的冲突与否进行检测,如果发现冲突了,则返回错误信息,让用户决定如何操作

悲观锁:

> 在操作数据时,认为此操作会出现数据冲突,所以在进行每次操作时,都需要通过获取锁才能进行对相同数据的操作,所以悲观锁需要消耗更多的时间 


2. 使用 

乐观锁:

> 乐观锁只是一个概念,并不是数据库自带的,需要用户代码去实现

![20200228174753-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200228174753-image.png)

- 表中的version字段是乐观锁在MySQL中的实现
- 更新前查询version

```
select id, version from stu where id = 1;
```

- 根据查询的version以及修改数据(若version被修改,本次更新失败)

```
update stu set name = 'Kobe', version = version + 1 where version = #{version} ;
```

> #{变量名} : 获取变量名对应的值 

悲观锁:

悲观锁的实现与乐观锁不同, 悲观锁是由数据库自己实现的,要用的时候,直接调用数据库相关语句,共享锁和排它锁是悲观锁的不同实现方式,它们俩都属于悲观锁

#### #1.4.3 共享锁和排它锁

1. 定义

共享锁: 

共享锁又称读锁(read lock),是读取操作创建的锁,其他用户可以并发读取数据,但任何数据都不能对数据进行修改,直到已释放所有共享锁

排它锁:

排它锁又称写锁(write lock),若某个事务对某一行数据加上排它锁,只能这个事务进行写操作,在此事务结束之前,其他事务不能对其加任何锁,其他进程可以读取,但不能进行写操作


### #1.5 SQL

#### #1.5.1 SQL语句

- 建库


```python
// 创建名为students的库
create database students;
```

- 删库

```python
// 删除名为students的库
drop database students;
```

- 建表

```python
// 创建名为stu的表
create table if not exists stu(
    Sid varchar(10),
    Sname char(10)
);
```

- 增

```python
// 插入数据 
insert into stu values('001','Kobe');
```

- 删

```python
// 删除数据 
delete from stu where Sid = '002';
```

```python
// 清空这个表数据 
truncat table stu;
```

- 改

```python
// 修改数据 
update stu set Sname = 'Kobe' where Sid = '008';
```

- 查

```python
// 查询数据 
select * from stu where Sname like 'Kobe%';
```



#### #1.5.2 CHAR和VARCHAR的区别？

- CHAR和VARCHAR类型在存储和检索方面有所不同
- CHAR列长度固定为创建表时声明的长度，长度值范围是1到255
- 当CHAR值被存储时，它们被用空格填充到特定长度，检索CHAR值时需删除尾随空格


#### #1.5.3 主键和候选键有什么区别？

- 表格的每一行都由主键唯一标识,一个表只有一个主键。
- 主键也是候选键。按照惯例，候选键可以被指定为主键，并且可以用于任何外键引用。

#### 1.5.4 myisamchk是用来做什么的？

它用来压缩MyISAM表，这减少了磁盘或内存使用。


#### #1.5.5 列设置为AUTO INCREMENT时，如果在表中达到最大值，会发生什么情况？

它会停止递增，任何进一步的插入都将产生错误，因为密钥已被使用。

#### #1.5.6 怎样才能找出最后一次插入时分配了哪个自动增量？

LAST_INSERT_ID将返回由Auto_increment分配的最后一个值，并且不需要指定表名称。


#### #1.5.7 LIKE声明中的％和_是什么意思？

％对应于0个或更多字符，_只是LIKE语句中的一个字符。


#### #1.5.8 NOW（）和CURRENT_DATE（）有什么区别？

- NOW（）命令用于显示当前年份，月份，日期，小时，分钟和秒。

- CURRENT_DATE（）仅显示当前年份，月份和日期。

#### #1.5.9 什么是非标准字符串类型？

- TINYTEXT
- TEXT
- MEDIUMTEXT
- LONGTEXT

#### #1.5.10 什么是通用SQL函数？

- CONCAT(A, B) – 连接两个字符串值以创建单个字符串输出。通常用于将两个或多个字段合并为一个字段。
- FORMAT(X, D)- 格式化数字X到D有效数字。
- CURRDATE(), CURRTIME()- 返回当前日期或时间。
- NOW（） – 将当前日期和时间作为一个值返回。
- MONTH（），DAY（），YEAR（），WEEK（），WEEKDAY（） – 从日期值中提取给定数据。
- HOUR（），MINUTE（），SECOND（） – 从时间值中提取给定数据。
- DATEDIFF（A，B） – 确定两个日期之间的差异，通常用于计算年龄
- SUBTIMES（A，B） – 确定两次之间的差异。
- FROMDAYS（INT） – 将整数天数转换为日期值。

#### #1.5.11 SQL注入漏洞产生的原因？如何防止？


> SQL注入产生的原因：程序开发过程中不注意规范书写sql语句和对特殊字符进行过滤，导致客户端可以通过全局变量POST和GET提交一些sql语句正常执行。


防止SQL注入的方式：

1. 开启配置文件中的magic_quotes_gpc 和 magic_quotes_runtime设置
2. 执行sql语句时使用addslashes进行sql语句转换
3. Sql语句书写尽量不要省略双引号和单引号。
4. 过滤掉sql语句中的一些关键词：update、insert、delete、select、 * 。
5. 提高数据库表和字段的命名技巧，对一些重要的字段根据程序的特点命名，取不易被猜到的。


### #1.6 优化

#### #1.6.1 SQL语句优化有哪些方法？

- Where子句中：where表之间的连接必须写在其他Where条件之前，那些可以过滤掉最大数量记录的条件必须写在Where子句的末尾.HAVING最后。
- 用EXISTS替代IN、用NOT EXISTS替代NOT IN。
- 避免在索引列上使用计算
- 避免在索引列上使用IS NULL和IS NOT NULL
- 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
- 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描
- 避免在开头使用模糊查询（%），该查询数据库引擎会放弃索引进行全表扫描,索引失效
- 如果表名或列名过长，就使用别名，因为长的表名和列名也会消耗扫描时间。
- 应尽量避免在 where子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描
- 减少使用 * ，用列名代替

```
select * from user;

要写成: 
select userID, userName, userSalary from user;
```

> 因为在使用 * 的时候，数据库还得查询数据字典，进而解析得到列名，而直接写出列名效率会更高些。


#### #1.6.2 Mysql如何优化DISTINCT？

DISTINCT在所有列上转换为GROUP BY，并与ORDER BY子句结合使用。

```
SELECT DISTINCT t1.a FROM t1,t2 where t1.a=t2.a;
```


#### #1.6.3 MySQL数据库作发布系统的存储，一天五万条以上的增量，预计运维三年,怎么优化？

- 设计良好的数据库结构，允许部分数据冗余，尽量避免join查询，提高效率。
- 选择合适的表字段数据类型和存储引擎，适当的添加索引。
- mysql库主从读写分离。
- 找规律分表，减少单表中的数据量提高查询速度。
- 添加缓存机制，比如memcached，apc等。
- 不经常改动的页面，生成静态页面。
- 书写高效率的SQL。比如 SELECT * FROM TABEL 改为 SELECT field_1, field_2, field_3 FROM TABLE.


#### #1.6.4 锁的优化策略


- 读写分离
- 分段加锁
- 减少锁持有的时间
- 多个线程尽量以相同的顺序去获取资源

不能将锁的粒度过于细化，不然可能会出现线程的加锁和释放次数过多，反而效率不如一次加一把大锁。


#### #1.6.5 索引的底层实现原理和优化


B+树，经过优化的B+树

主要是在所有的叶子结点中增加了指向下一个叶子节点的指针，因此InnoDB建议为大部分表使用默认自增的主键作为主索引。

### #1.7 分布式

#### #1.7.1 为什么要MySQL主从

为了减轻服务器处理海量数据并发锁产生的性能问题,其中最主流的方案就是读写分离

#### #1.7.2 MySQL读写分离流程

![20200228184947-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200228184947-image.png)

- MySQL主服务器对数据操作记录在二进制日志文件(Binary log)中,MySQL将事务串行的写入二进制日志文件
- Slave从服务器将二进制日志文件(Binary log)拷贝到中继日志文件(Relay log)中,首先,Slave开启一个工作线程(I/O thread),具体如下:
1. Slave开启一个工作线程(I/O thread),I/O线程在Master上打开一个连接
2. 开始 binary dump process
3. 如果 binary dump process 已经同步,它会睡眠等待master产生新的事件
4. I/O线程将这些事件写入中继日志文件中
5. SQL Slave thread 从中继文件读取事件,并重放其中的事件而更新Slave数据,使其与Master中的数据一致

#### #1.7.3 为什么需要中继文件

由于网络原因, Binary log 不可能一口气存到 I/O thread中,所以Relay log用来缓存Binary log的事件,且Relay log存储在从服务器的缓存中,开销比较小 

#### #1.7.4 主从同步的有点

- 主库写,从库读,降低服务器压力
- 在从服务器进行备份,避免备份期间影响主武器,保证数据安全
- 当主服务器出现问题时,可以切换到从服务器,提高性能



---

## #2 数据库Redis 

### #2.1 Redis数据结构

#### #2.1.1 Redis支持哪几种数据类型？

- String(字符串)
- List(列表)
- Set(集合)
- Sorted Set(有序集合)
- hashes(哈希)


### #2.2 Redis 主从

### #2.2.1 什么是Redis 主从同步

Redis主从同步。数据可以从主服务器向任意数量的从服务器上同步，从服务器可以是关联其他从服务器的主服务器。这使得Redis可执行单层树复制。存盘可以有意无意的对数据进行写操作。由于完全实现了发布/订阅机制，使得从数据库在任何地方同步树时，可订阅一个频道并接收主服务器完整的消息发布 记录。同步对读取操作的可扩展性和数据冗余很有帮助。


### #2.2.2 Redis主从工作原理

Redis的主从结构可以采用一主多从或者级联结构，Redis主从复制可以根据是否是全量分为全量同步和增量同步。

1. 全量同步

Redis全量复制一般发生在Slave初始化阶段，这时Slave需要将Master上的所有数据都复制一份。具体步骤如下： 

- 从服务器连接主服务器，发送SYNC命令；
- 主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令；
- 主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令；
- 从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；
- 主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；
- 从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；





### #2.2 Redis集群

#### #2.2.1 Redis集群方案应该怎么做？都有哪些方案？

- twemproxy，大概概念是，它类似于一个代理方式，使用方法和普通redis无任何区别，设置好它下属的多个redis实例后，使用时在本需要连接redis的地方改为连接twemproxy，它会以一个代理的身份接收请求并使用一致性hash算法，将请求转接到具体redis，将结果再返回twemproxy。使用方式简便(相对redis只需修改连接端口)，对旧项目扩展的首选。 问题：twemproxy自身单端口实例的压力，使用一致性hash后，对redis节点数量改变时候的计算值的改变，数据无法自动移动到新的节点。
- codis，目前用的最多的集群方案，基本和twemproxy一致的效果，但它支持在 节点数量改变情况下，旧节点数据可恢复到新hash节点。
- redis cluster3.0自带的集群，特点在于他的分布式算法不是一致性hash，而是hash槽的概念，以及自身支持节点设置从节点。具体看官方文档介绍。
- 在业务代码层实现，起几个毫无关联的redis实例，在代码层，对key 进行hash计算，然后去对应的redis实例操作数据。 这种方式对hash层代码要求比较高，考虑部分包括，节点失效后的替代算法方案，数据震荡后的自动脚本恢复，实例的监控，等等。

#### #2.2.2 Redis集群方案什么情况下会导致整个集群不可用？

有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用。


#### #2.2.3 Redis集群的主从复制模型是怎样的？

为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品.

#### #2.2.4 Redis集群会有写操作丢失吗？为什么？

Redis并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。

#### #2.2.5 Redis集群之间是如何复制的？

异步复制





### #2.3 Redis单线程 


### #2.4 Redis异常处理

#### #2.4.1 Redis内存满了的几种解决方法

1. 增加内存
2. 使用内存淘汰策略
3. Redis集群

> 增加内存

redis设置配置文件的maxmemory参数，可以控制其最大可用内存大小（字节）

> 使用内存淘汰策略

配置文件中maxmemory-policy可以设置删除redis键

规则名称 | 规则说明
---|---
volatile-lru | 使用LRU算法删除一个键（只对设置了生存时间的键）
allkeys-lru | 使用LRU算法删除一个键
volatile-random | 随机删除一个键（只对设置了生存时间的键）
allkeys-random | 随机删除一个键
volatile-ttl | 删除生存时间最近的一个键
noeviction (默认) | 不删除键，只返回错误

LRU算法，least RecentlyUsed，最近最少使用算法。也就是说默认删除最近最少使用的键。

但是一定要注意一点！redis中并不会准确的删除所有键中最近最少使用的键，而是随机抽取3个键，删除这三个键中最近最少使用的键。
那么3这个数字也是可以设置的，对应位置是配置文件中的maxmeory-samples.

> Redis集群

Redis仅支持单实例，内存一般最多10~20GB。对于内存动辄100~200GB的系统，就需要通过集群来支持了。

Redis集群有三种方式：客户端分片、代理分片、RedisCluster


### #2.5 Redis特点

#### #2.5.1 Redis相比memcached有哪些优势？

- memcached所有的值均是简单的字符串，redis作为其替代者， 支持更为丰富的数据类型
- redis的速度比memcached快很多
- redis可以持久化其数据

#### #2.5.2 为什么Redis需要把所有数据放到内存中？

Redis为了达到最快的读写速度将数据都读到内存中，并通过异步的方式将数据写入磁盘。所以redis具有快速和数据持久化的特征。如果不将数据放在内存中，磁盘I/O速度为严重影响redis的性能。在内存越来越便宜的今天，redis将会越来越受欢迎。

#### #2.5.3 Redis有哪些适合的场景？

- 会话缓存（Session Cache）最常用的一种使用Redis的情景是会话缓存（session cache）。用Redis缓存会话比其他存储（如Memcached）的优势在于：Redis提供持久化。当维护一个不是严格要求一致性的缓存时，如果用户的购物车信息全部丢失，大部分人都会不高兴的，现在，他们还会这样吗？幸运的是，随着 Redis 这些年的改进，很容易找到怎么恰当的使用Redis来缓存会话的文档。甚至广为人知的商业平台Magento也提供Redis的插件。
- 全页缓存（FPC）除基本的会话token之外，Redis还提供很简便的FPC平台。回到一致性问题，即使重启了Redis实例，因为有磁盘的持久化，用户也不会看到页面加载速度的下降，这是一个极大改进，类似PHP本地FPC。再次以Magento为例，Magento提供一个插件来使用Redis作为全页缓存后端。此外，对WordPress的用户来说，Pantheon有一个非常好的插件 wp-redis，这个插件能帮助你以最快速度加载你曾浏览过的页面。
- 队列Reids在内存存储引擎领域的一大优点是提供 list 和 set 操作，这使得Redis能作为一个很好的消息队列平台来使用。Redis作为队列使用的操作，就类似于本地程序语言（如Python）对 list 的 push/pop 操作。如果你快速的在Google中搜索“Redis queues”，你马上就能找到大量的开源项目，这些项目的目的就是利用Redis创建非常好的后端工具，以满足各种队列需求。例如，Celery有一个后台就是使用Redis作为broker，你可以从这里去查看。
- 排行榜/计数器Redis在内存中对数字进行递增或递减的操作实现的非常好。集合（Set）和有序集合（Sorted Set）也使得我们在执行这些操作的时候变的非常简单，Redis只是正好提供了这两种数据结构。所以，我们要从排序集合中获取到排名最靠前的10个用户–我们称之为“user_scores”，我们只需要像下面一样执行即可：当然，这是假定你是根据你用户的分数做递增的排序。如果你想返回用户及用户的分数，你需要这样执行：ZRANGE user_scores 0 10 WITHSCORESAgora Games就是一个很好的例子，用Ruby实现的，它的排行榜就是使用Redis来存储数据的，你可以在这里看到。
- 发布/订阅最后（但肯定不是最不重要的）是Redis的发布/订阅功能。发布/订阅的使用场景确实非常多。我已看见人们在社交网络连接中使用，还可作为基于发布/订阅的脚本触发器，甚至用Redis的发布/订阅功能来建立聊天系统！（不，这是真的，你可以去核实）。


#### #2.5.4 MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据？

redis内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。

#### #2.5.5 Redis回收进程如何工作的？

一个客户端运行了新的命令，添加了新的数据。Redi检查内存使用情况，如果大于maxmemory的限制, 则根据设定好的策略进行回收。一个新的命令被执行，等等。所以我们不断地穿越内存限制的边界，通过不断达到边界然后不断地回收回到边界以下。如果一个命令的结果导致大量内存被使用（例如很大的集合的交集保存到一个新的键），不用多久内存限制就会被这个内存使用量超越。

#### #2.5.6 为什么要做Redis分区？

分区可以让Redis管理更大的内存，Redis将可以使用所有机器的内存。如果没有分区，你最多只能使用一台机器的内存。分区使Redis的计算能力通过简单地增加计算机得到成倍提升,Redis的网络带宽也会随着计算机和网卡的增加而成倍增长。

#### #2.5.7 Redis分区有什么缺点？

涉及多个key的操作通常不会被支持。例如你不能对两个集合求交集，因为他们可能被存储到不同的Redis实例（实际上这种情况也有办法，但是不能直接使用交集指令）。同时操作多个key,则不能使用Redis事务.分区使用的粒度是key，不能使用一个非常长的排序key存储一个数据集（The partitioning granularity is the key, so it is not possible to shard a dataset with a single huge key like a very big sorted set）.当使用分区的时候，数据处理会非常复杂，例如为了备份你必须从不同的Redis实例和主机同时收集RDB / AOF文件。分区时动态扩容或缩容可能非常复杂。Redis集群在运行时增加或者删除Redis节点，能做到最大程度对用户透明地数据再平衡，但其他一些客户端分区或者代理分区方法则不支持这种特性。然而，有一种预分片的技术也可以较好的解决这个问题。

#### #2.5.8 Redis的内存占用情况怎么样？

给你举个例子： 100万个键值对（键是0到999999值是字符串“hello world”）在我的32位的Mac笔记本上 用了100MB。同样的数据放到一个key里只需要16MB， 这是因为键值有一个很大的开销。 在Memcached上执行也是类似的结果，但是相对Redis的开销要小一点点，因为Redis会记录类型信息引用计数等等。当然，大键值对时两者的比例要好很多。64位的系统比32位的需要更多的内存开销，尤其是键值对都较小时，这是因为64位的系统里指针占用了8个字节。 但是，当然，64位系统支持更大的内存，所以为了运行大型的Redis服务器或多或少的需要使用64位的系统。

#### #2.5.9 一个Redis实例最多能存放多少的keys？

List、Set、Sorted Set他们最多能存放多少元素？理论上Redis可以处理多达232的keys，并且在实际中进行了测试，每个实例至少存放了2亿5千万的keys。我们正在测试一些较大的值。任何list、set、和sorted set都可以放232个元素。换句话说，Redis的存储极限是系统中的可用内存值。


### #2.6 Redis优化

#### #2.6.1 Redis如何做内存优化？

尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面.

#### #2.6.2 Redis常见性能问题和解决方案？

- Master最好不要做任何持久化工作，如RDB内存快照和AOF日志文件
- 如果数据比较重要，某个Slave开启AOF备份数据，策略设置为每秒同步一次
- 为了主从复制的速度和连接的稳定性，Master和Slave最好在同一个局域网内
- 尽量避免在压力很大的主库上增加从库
- 主从复制不要用图状结构，用单向链表结构更为稳定，即：Master <- Slave1 <- Slave2 <- Slave3...这样的结构方便解决单点故障问题，实现Slave对Master的替换。如果Master挂了，可以立刻启用Slave1做Master，其他不变。


### #2.7 Redis持久化 

#### #2.7.1 Redis提供了哪几种持久化方式？

RDB持久化方式能够在指定的时间间隔能对你的数据进行快照存储.AOF持久化方式记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据,AOF命令以redis协议追加保存每次写的操作到文件末尾.Redis还能对AOF文件进行后台重写,使得AOF文件的体积不至于过大.如果你只希望你的数据在服务器运行的时候存在,你也可以不使用任何持久化方式.你也可以同时开启两种持久化方式, 在这种情况下, 当redis重启的时候会优先载入AOF文件来恢复原始的数据,因为在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整.最重要的事情是了解RDB和AOF持久化方式的不同,让我们以RDB持久化方式开始。


#### #2.7.2 如何选择合适的持久化方式？

一般来说， 如果想达到足以媲美PostgreSQL的数据安全性， 你应该同时使用两种持久化功能。如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失，那么你可以只使用RDB持久化。有很多用户都只使用AOF持久化，但并不推荐这种方式：因为定时生成RDB快照（snapshot）非常便于进行数据库备份， 并且 RDB 恢复数据集的速度也要比AOF恢复的速度要快，除此之外， 使用RDB还可以避免之前提到的AOF程序的bug。


---
---
---
---





























## #3 Python

### #3.1 列出5个python标准库

- os：提供了不少与操作系统相关联的函数
- sys: 通常用于命令行参数
- re: 正则匹配
- math: 数学运算
- datetime:处理日期时间

### #3.2 python的GIL

GIL 是python的全局解释器锁，同一进程中假如有多个线程运行，一个线程在运行python程序的时候会霸占python解释器（加了一把锁即GIL），使该进程内的其他线程无法运行，等该线程运行完后其他线程才能运行。如果线程运行过程中遇到耗时操作，则解释器锁解开，使其他线程运行。所以在多线程中，线程的运行仍是有先后顺序的，并不是同时进行。

多进程中因为每个进程都能被系统分配资源，相当于每个进程有了一个python解释器，所以多进程可以实现多个进程的同时运行，缺点是进程系统资源开销大

### #3.3 面向对象中__new__和__init__区别

> __init__

- __init__是初始化方法，创建对象后，就立刻被默认调用了，可接收参数


> __new__

- __new__至少要有一个参数cls，代表当前类，此参数在实例化时由Python解释器自动识别
- __new__必须要有返回值，返回实例化出来的实例，这点在自己实现__new__时要特别注意，可以return父类（通过super(当前类名, cls)）__new__出来的实例，或者直接是object的__new__出来的实例


区别: 

- __init__有一个参数self，就是这个__new__返回的实例，__init__在__new__的基础上可以完成一些其它初始化的动作，__init__不需要返回值
- 如果__new__创建的是当前类的实例，会自动调用__init__函数，通过return语句里面调用的__new__函数的第一个参数是cls来保证是当前类实例，如果是其他类的类名，；那么实际创建返回的就是其他类的实例，其实就不会调用当前类的__init__函数，也不会调用其他类的__init__函数



### #3.4 简述with方法打开处理文件帮我我们做了什么？

打开文件在进行读写的时候可能会出现一些异常状况，如果按照常规的f.open

写法，我们需要try,except,finally，做异常判断，并且文件最终不管遇到什么情况，都要执行finally f.close()关闭文件，with方法帮我们实现了finally中f.close

### #3.5 python垃圾回收机制

python垃圾回收主要以引用计数为主，标记-清除和分代清除为辅的机制，其中标记-清除和分代回收主要是为了处理循环引用的难题。


引用计数算法: 

当有1个变量保存了对象的引用时，此对象的引用计数就会加1

当使用del删除变量指向的对象时，如果对象的引用计数不为1，比如3，那么此时只会让这个引用计数减1，即变为2，当再次调用del时，变为1，如果再调用1次del，此时会真的把对象进行删除



















## #4 计算机网络

### #4.1 计算机网络7层模型



![20200227173257-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200227173257-image.png)

---

![20200227174046-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200227174046-image.png)

**各层功能:** 

1. 应用层(http协议，DNS协议)：

> 请求报文格式：

- GET　/http://www.sohu.com HTTP/1.1 请求行，只不过这里被分开了，请求的方式  URL　版本
- Host：主机名 www.solu.com
- User-Agent：使用什么代理服务器，这里就是FireFox，也就是火狐
- Accept：能接收的数据类型有哪些
- Accept-Language：表示用户希望优先想得到的版本，一次排列下去，先是中文，再是英文
- Accept-Encoding：通知服务端可以发送的数据压缩格式
- Cookie：浏览器端的一个技术，在服务器上记录用户信息，但是也会在浏览器中保存一份。
- Connection：连接的方式，有两种，非持续连接和持续连接，非持续连接


> 响应报文状态码：

- 1xx：表示通知信息的，比如请求收到了或正在进行处理
- 2xx：表示成功，也就是服务器接收到了你的请求，并成功处理了，一般最喜欢看到的就是200了。200：这次请求成功了。
- 3xx：表示重定向，服务器告诉浏览器要完成请求你必须采取进一步的行动，也就是去访问另一个网页，
- 4xx：表示客户的差错，比如请求中有错误的语法或不能完成.404错误：找不到资源，你的URL写的有错误，使定位不到正确的资源
- 5xx：服务器的差错，如服务器失效，或者内部出现异常不能完成你的请求. 500错误：就是服务器写的代码中有问题。


2. 运输层（UDP和TCP三次握手，四次挥手）

> UDP：

- 无连接：意思就是在通讯之前不需要建立连接，直接传输数据。
- 不可靠：是将数据报的分组从一台主机发送到另一台主机，但并不保证数据报能够到达另一端，任何必须的可靠性都由应用程序提供。

> TCP

- TCP协议是面向连接的、可靠传输、有流量控制，拥塞控制，面向字节流传输等很多优点的协议。


3. 网络层（ip协议等）：

IP协议（用来规定数据报的格式），IP地址，

![20200227173642-image.png](https://raw.githubusercontent.com/Coxhuang/yosoro/master/20200227173642-image.png)


4. 数据链路层（网络连接）：

以太网，局域网，集线器和网桥等。

5. 物理层（数据传输媒介和原理）：


机械特性、电气特性、功能特性、过程特性









## #5 B树 


## #6 线程  











